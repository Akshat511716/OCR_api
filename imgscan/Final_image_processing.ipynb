{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Super Resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from PIL import Image\n",
    "# import PIL\n",
    "# import cv2\n",
    "# import time\n",
    "\n",
    "# img = cv2.imread('../temp/corrected.jpg')\n",
    "# width = img.shape[1]\n",
    "# height = img.shape[0]\n",
    "# bicubic = cv2.resize(img,(width*4,height*4))\n",
    "# # cv2.imshow('Image',img)\n",
    "# # cv2.imshow('BICUBIC',bicubic)\n",
    "\n",
    "# super_res = cv2.dnn_superres.DnnSuperResImpl_create()\n",
    "\n",
    "# # start = time.time()\n",
    "# # super_res.readModel('LapSRN_x4.pb')\n",
    "# # super_res.setModel('lapsrn',4)\n",
    "# # lapsrn_image = super_res.upsample(img)\n",
    "# # end = time.time()\n",
    "# # print('Time taken in seconds by lapsrn', end-start)\n",
    "# # cv2.imshow('LAPSRN',lapsrn_image)\n",
    "\n",
    "# start = time.time()\n",
    "# super_res.readModel('EDSR_x4.pb')\n",
    "# super_res.setModel('edsr',4)\n",
    "# edsr_image = super_res.upsample(img)\n",
    "# end = time.time()\n",
    "# print('Time taken in seconds by edsr', end-start)\n",
    "# # cv2.imshow('EDSR',edsr_image)\n",
    "\n",
    "# cv2.imwrite(\"../temp/upscaled.jpg\", edsr_image)\n",
    "\n",
    "# # cv2.waitKey(0)\n",
    "# # cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perspective Correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "from cvtools import resize\n",
    "from cvtools import perspective_transform\n",
    "from cvtools import getoutlines\n",
    "from cvtools import simple_erode\n",
    "from cvtools import simple_dilate\n",
    "from cvtools import brightness_contrast\n",
    "from cvtools import blank\n",
    "\n",
    "# READ INPUT IMAGE\n",
    "img = cv2.imread(\"../temp/image.jpg\")\n",
    "\n",
    "try:\n",
    "    # if input image is empty, notify the user and quit program\n",
    "    if img is None:\n",
    "        print()\n",
    "        print(\"The file does not exist or is empty!\")\n",
    "        print(\"Please select a valid image file!\")\n",
    "        print()\n",
    "        exit(0)  # exit code zero means a clean exit with no output/errors etc.\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    Primary Functions\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    def preprocess(img):\n",
    "        \"\"\"\n",
    "        BAISC PRE-PROCESSING TO OBTAIN A CANNY EDGE IMAGE\n",
    "        \"\"\"\n",
    "\n",
    "        # increase contrast between paper and background\n",
    "        img_adj = brightness_contrast(img, 1.56, -60)\n",
    "\n",
    "        # calculate the ratio of the image to the new height (500px) so we\n",
    "        # can scale the manipulated image back to the original size later\n",
    "        scale = img_adj.shape[0] / 500.0\n",
    "\n",
    "        # scale the image down to 500px in height;\n",
    "        img_scaled = resize(img_adj, height=500)\n",
    "\n",
    "        # convert image to grayscale\n",
    "        img_gray = cv2.cvtColor(img_scaled, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # apply gaussian blur with a 11x11 kernel\n",
    "        img_gray = cv2.GaussianBlur(img_gray, (11, 11), 0)\n",
    "\n",
    "        # apply canny edge detection\n",
    "        img_edge = cv2.Canny(img_gray, 60, 245)\n",
    "\n",
    "        # dilate the edge image to connect any small gaps\n",
    "        img_edge = simple_dilate(img_edge)\n",
    "\n",
    "        return img_adj, scale, img_scaled, img_edge\n",
    "\n",
    "\n",
    "    def gethull(img_edge):\n",
    "        \"\"\"\n",
    "        1st ROUND OF OUTLINE FINDING, + CONVEX HULL\n",
    "        \"\"\"\n",
    "\n",
    "        # make a copy of the edge image because the following function manipulates\n",
    "        # the input\n",
    "        img_prehull = img_edge.copy()\n",
    "\n",
    "        # find outlines in the (newly copied) edge image\n",
    "        outlines = getoutlines(img_prehull)\n",
    "\n",
    "        # create a blank image for convex hull operation\n",
    "        img_hull = blank(img_prehull.shape, img_prehull.dtype, \"0\")\n",
    "\n",
    "        # draw convex hulls (fit polygon) for all outlines detected to 'img_contour'\n",
    "        for outline in range(len(outlines)):\n",
    "\n",
    "            hull = cv2.convexHull(outlines[outline])\n",
    "\n",
    "            # parameters: source image, outlines (contours),\n",
    "            #             contour index (-1 for all), color, thickness\n",
    "            cv2.drawContours(img_hull, [hull], 0, 255, 3)\n",
    "\n",
    "        # erode the hull image to make the outline closer to paper\n",
    "        img_hull = simple_erode(img_hull)\n",
    "\n",
    "        return img_hull\n",
    "\n",
    "\n",
    "    def getcorners(img_hull):\n",
    "        \"\"\"\n",
    "        2nd ROUND OF OUTLINE FINDING, + SORTING & APPROXIMATION\n",
    "        \"\"\"\n",
    "\n",
    "        # make a copy of the edge image because the following function manipulates\n",
    "        # the input\n",
    "        img_outlines = img_hull.copy()\n",
    "\n",
    "        # find outlines in the convex hull image\n",
    "        outlines = getoutlines(img_outlines)\n",
    "\n",
    "        # sort the outlines by area from large to small, and only take the largest 4\n",
    "        # outlines in order to speed up the process and not waste time\n",
    "        outlines = sorted(outlines, key=cv2.contourArea, reverse=True)[:4]\n",
    "\n",
    "        # loop over outlines\n",
    "        for outline in outlines:\n",
    "\n",
    "            # find the perimeter of each outline for use in approximation\n",
    "            perimeter = cv2.arcLength(outline, True)\n",
    "\n",
    "            # > approximate a rough contour for each outline found, with (hopefully)\n",
    "            #   4 points (rectangular sheet of paper); [Douglas-Peuker Algorithm]\n",
    "            # > FIRST OPTION is the input outline;\n",
    "            # > SECOND OPTION is the accuracy of approximation (epsilon), here it\n",
    "            #   is set to a percentage of the perimeter of the outline\n",
    "            # > THIRD OPTION is whether to assume an outline\n",
    "            #   is closed, which in this case is yes (sheet of paper)\n",
    "            approx = cv2.approxPolyDP(outline, 0.02 * perimeter, True)\n",
    "\n",
    "            # if the approximation has 4 points, then assume it is correct, and\n",
    "            # assign these points to the 'corners' variable\n",
    "            if len(approx) == 4:\n",
    "                corners = approx\n",
    "                break\n",
    "\n",
    "        return corners\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    Main Proccess of the Program\n",
    "    \"\"\"\n",
    "\n",
    "    # obtain the adjusted image, scaled image along with its scale factor, and the\n",
    "    # Canny edge image\n",
    "    img_adj, scale, img_scaled, img_edge = preprocess(img)\n",
    "\n",
    "    # perform convex hull on edge image to prevent imcomplete outline\n",
    "    img_hull = gethull(img_edge)\n",
    "\n",
    "    # obtain 4 corner points of the convex hull image\n",
    "    corners = getcorners(img_hull)\n",
    "\n",
    "    # scale the corner points back to the original size of the image using the scale\n",
    "    # calculated previously\n",
    "    corners = corners.reshape(4, 2) * scale\n",
    "\n",
    "    # finally correct the perspective of the image by applying four-point\n",
    "    # perspective transform\n",
    "    img_corrected = perspective_transform(img_adj, corners)\n",
    "\n",
    "    # write corrected image to file\n",
    "    cv2.imwrite(\"../temp/corrected.jpg\", img_corrected)\n",
    "except:\n",
    "    cv2.imwrite(\"../temp/corrected.jpg\", img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perspective Correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# import cv2\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# def get_destination_points(corners):\n",
    "#     \"\"\"\n",
    "#     -Get destination points from corners of warped images\n",
    "#     -Approximating height and width of the rectangle: we take maximum of the 2 widths and 2 heights\n",
    "#     Args:\n",
    "#         corners: list\n",
    "#     Returns:\n",
    "#         destination_corners: list\n",
    "#         height: int\n",
    "#         width: int\n",
    "#     \"\"\"\n",
    "\n",
    "#     w1 = np.sqrt((corners[0][0] - corners[1][0]) ** 2 + (corners[0][1] - corners[1][1]) ** 2)\n",
    "#     w2 = np.sqrt((corners[2][0] - corners[3][0]) ** 2 + (corners[2][1] - corners[3][1]) ** 2)\n",
    "#     w = max(int(w1), int(w2))\n",
    "\n",
    "#     h1 = np.sqrt((corners[0][0] - corners[2][0]) ** 2 + (corners[0][1] - corners[2][1]) ** 2)\n",
    "#     h2 = np.sqrt((corners[1][0] - corners[3][0]) ** 2 + (corners[1][1] - corners[3][1]) ** 2)\n",
    "#     h = max(int(h1), int(h2))\n",
    "\n",
    "#     destination_corners = np.float32([(0, 0), (w - 1, 0), (0, h - 1), (w - 1, h - 1)])\n",
    "\n",
    "# #     print('\\nThe destination points are: \\n')\n",
    "#     for index, c in enumerate(destination_corners):\n",
    "#         character = chr(65 + index) + \"'\"\n",
    "# #         print(character, ':', c)\n",
    "\n",
    "# #     print('\\nThe approximated height and width of the original image is: \\n', (h, w))\n",
    "#     return destination_corners, h, w\n",
    "\n",
    "# def unwarp(img, src, dst):\n",
    "#     \"\"\"\n",
    "#     Args:\n",
    "#         img: np.array\n",
    "#         src: list\n",
    "#         dst: list\n",
    "#     Returns:\n",
    "#         un_warped: np.array\n",
    "#     \"\"\"\n",
    "#     h, w = img.shape[:2]\n",
    "#     H, _ = cv2.findHomography(src, dst, method=cv2.RANSAC, ransacReprojThreshold=3.0)\n",
    "# #     print('\\nThe homography matrix is: \\n', H)\n",
    "#     un_warped = cv2.warpPerspective(img, H, (w, h), flags=cv2.INTER_LINEAR)\n",
    "\n",
    "#     # plot\n",
    "\n",
    "# #     f, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 8))\n",
    "#     # f.subplots_adjust(hspace=.2, wspace=.05)\n",
    "# #     ax1.imshow(img)\n",
    "# #     ax1.set_title('Original Image')\n",
    "\n",
    "#     x = [src[0][0], src[2][0], src[3][0], src[1][0], src[0][0]]\n",
    "#     y = [src[0][1], src[2][1], src[3][1], src[1][1], src[0][1]]\n",
    "\n",
    "# #     ax2.imshow(img)\n",
    "# #     ax2.plot(x, y, color='yellow', linewidth=3)\n",
    "# #     ax2.set_ylim([h, 0])\n",
    "# #     ax2.set_xlim([0, w])\n",
    "# #     ax2.set_title('Target Area')\n",
    "\n",
    "# #     plt.show()\n",
    "#     return un_warped\n",
    "\n",
    "# def apply_filter(image):\n",
    "#     \"\"\"\n",
    "#     Define a 5X5 kernel and apply the filter to gray scale image\n",
    "#     Args:\n",
    "#         image: np.array\n",
    "#     Returns:\n",
    "#         filtered: np.array\n",
    "#     \"\"\"\n",
    "#     gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "#     kernel = np.ones((5, 5), np.float32) / 15\n",
    "#     filtered = cv2.filter2D(gray, -1, kernel)\n",
    "# #     plt.imshow(cv2.cvtColor(filtered, cv2.COLOR_BGR2RGB))\n",
    "# #     plt.title('Filtered Image')\n",
    "# #     plt.show()\n",
    "#     return filtered\n",
    "\n",
    "# def apply_threshold(filtered):\n",
    "#     \"\"\"\n",
    "#     Apply OTSU threshold\n",
    "#     Args:\n",
    "#         filtered: np.array\n",
    "#     Returns:\n",
    "#         thresh: np.array\n",
    "#     \"\"\"\n",
    "#     ret, thresh = cv2.threshold(filtered, 250, 255, cv2.THRESH_OTSU)\n",
    "# #     plt.imshow(cv2.cvtColor(thresh, cv2.COLOR_BGR2RGB))\n",
    "# #     plt.title('After applying OTSU threshold')\n",
    "# #     plt.show()\n",
    "#     return thresh\n",
    "\n",
    "# def detect_contour(img, image_shape):\n",
    "#     \"\"\"\n",
    "#     Args:\n",
    "#         img: np.array()\n",
    "#         image_shape: tuple\n",
    "#     Returns:\n",
    "#         canvas: np.array()\n",
    "#         cnt: list\n",
    "#     \"\"\"\n",
    "#     canvas = np.zeros(image_shape, np.uint8)\n",
    "#     contours, hierarchy = cv2.findContours(img, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)\n",
    "#     cnt = sorted(contours, key=cv2.contourArea, reverse=True)[0]\n",
    "#     cv2.drawContours(canvas, cnt, -1, (0, 255, 255), 3)\n",
    "# #     plt.title('Largest Contour')\n",
    "# #     plt.imshow(canvas)\n",
    "# #     plt.show()\n",
    "\n",
    "#     return canvas, cnt\n",
    "\n",
    "# def detect_corners_from_contour(canvas, cnt):\n",
    "#     \"\"\"\n",
    "#     Detecting corner points form contours using cv2.approxPolyDP()\n",
    "#     Args:\n",
    "#         canvas: np.array()\n",
    "#         cnt: list\n",
    "#     Returns:\n",
    "#         approx_corners: list\n",
    "#     \"\"\"\n",
    "#     epsilon = 0.02 * cv2.arcLength(cnt, True)\n",
    "#     approx_corners = cv2.approxPolyDP(cnt, epsilon, True)\n",
    "#     cv2.drawContours(canvas, approx_corners, -1, (255, 255, 0), 10)\n",
    "#     approx_corners = sorted(np.concatenate(approx_corners).tolist())\n",
    "# #     print('\\nThe corner points are ...\\n')\n",
    "#     for index, c in enumerate(approx_corners):\n",
    "#         character = chr(65 + index)\n",
    "# #         print(character, ':', c)\n",
    "#         cv2.putText(canvas, character, tuple(c), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2, cv2.LINE_AA)\n",
    "\n",
    "#     # Rearranging the order of the corner points\n",
    "#     approx_corners = [approx_corners[i] for i in [0, 2, 1, 3]]\n",
    "\n",
    "# #     plt.imshow(canvas)\n",
    "# #     plt.title('Corner Points: Douglas-Peucker')\n",
    "# #     plt.show()\n",
    "#     return approx_corners\n",
    "\n",
    "# def example_two():\n",
    "#     \"\"\"\n",
    "#     Skew correction using homography and corner detection using contour points\n",
    "#     Returns: None\n",
    "#     \"\"\"\n",
    "#     image = cv2.imread('../temp/image.jpg')\n",
    "#     image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "# #     plt.imshow(image)\n",
    "# #     plt.title('Original Image')\n",
    "# #     plt.show()\n",
    "\n",
    "#     filtered_image = apply_filter(image)\n",
    "#     threshold_image = apply_threshold(filtered_image)\n",
    "\n",
    "#     cnv, largest_contour = detect_contour(threshold_image, image.shape)\n",
    "#     corners = detect_corners_from_contour(cnv, largest_contour)\n",
    "\n",
    "#     destination_points, h, w = get_destination_points(corners)\n",
    "#     un_warped = unwarp(image, np.float32(corners), destination_points)\n",
    "\n",
    "#     cropped = un_warped[0:h, 0:w]\n",
    "# #     f, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 8))\n",
    "#     # f.subplots_adjust(hspace=.2, wspace=.05)\n",
    "# #     ax1.imshow(un_warped)\n",
    "# #     ax2.imshow(cropped)\n",
    "#     cropped = cv2.cvtColor(cropped, cv2.COLOR_BGR2RGB)\n",
    "#     cv2.imwrite(\"../temp/cropped.jpg\",cropped)\n",
    "\n",
    "# #     plt.show()\n",
    "\n",
    "# example_two()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 00: Opening an Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "image_file = \"../temp/corrected.jpg\"\n",
    "img = cv2.imread(image_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def display(im_path):\n",
    "#     dpi = 80\n",
    "#     im_data = plt.imread(im_path)\n",
    "\n",
    "#     height, width  = im_data.shape[:2]\n",
    "    \n",
    "#     # What size does the figure need to be in inches to fit the image?\n",
    "#     figsize = width / float(dpi), height / float(dpi)\n",
    "\n",
    "#     # Create a figure of the right size with one axes that takes up the full figure\n",
    "#     fig = plt.figure(figsize=figsize)\n",
    "#     ax = fig.add_axes([0, 0, 1, 1])\n",
    "\n",
    "#     # Hide spines, ticks, etc.\n",
    "#     ax.axis('off')\n",
    "\n",
    "#     # Display the image.\n",
    "#     ax.imshow(im_data, cmap='gray')\n",
    "\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display(image_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 01: Deskew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aksha\\AppData\\Local\\Temp\\ipykernel_1236\\2806705659.py:6: DeprecationWarning: Please use `rotate` from the `scipy.ndimage` namespace, the `scipy.ndimage.interpolation` namespace is deprecated.\n",
      "  data = inter.rotate(arr, angle, reshape=False, order=0)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.ndimage import interpolation as inter\n",
    "\n",
    "def correct_skew(image, delta=1, limit=5):\n",
    "    def determine_score(arr, angle):\n",
    "        data = inter.rotate(arr, angle, reshape=False, order=0)\n",
    "        histogram = np.sum(data, axis=1, dtype=float)\n",
    "        score = np.sum((histogram[1:] - histogram[:-1]) ** 2, dtype=float)\n",
    "        return histogram, score\n",
    "\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1] \n",
    "\n",
    "    scores = []\n",
    "    angles = np.arange(-limit, limit + delta, delta)\n",
    "    for angle in angles:\n",
    "        histogram, score = determine_score(thresh, angle)\n",
    "        scores.append(score)\n",
    "\n",
    "    best_angle = angles[scores.index(max(scores))]\n",
    "\n",
    "    (h, w) = image.shape[:2]\n",
    "    center = (w // 2, h // 2)\n",
    "    M = cv2.getRotationMatrix2D(center, best_angle, 1.0)\n",
    "    corrected = cv2.warpAffine(image, M, (w, h), flags=cv2.INTER_CUBIC, \\\n",
    "            borderMode=cv2.BORDER_REPLICATE)\n",
    "\n",
    "    return best_angle, corrected\n",
    "\n",
    "angle, corrected = correct_skew(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imwrite(\"../temp/result1.jpg\", corrected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 02: Inverted Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "inverted_image = cv2.bitwise_not(corrected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imwrite(\"../temp/result2.jpg\", inverted_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 03: Binarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grayscale(image):\n",
    "    return cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "gray_image = grayscale(inverted_image)\n",
    "\n",
    "thresh, im_bw = cv2.threshold(gray_image, 210, 230, cv2.THRESH_BINARY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imwrite(\"../temp/result3.jpg\", im_bw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 04: Noise Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def noise_removal(image):\n",
    "    import numpy as np\n",
    "    kernel = np.ones((1, 1), np.uint8)\n",
    "    image = cv2.dilate(image, kernel, iterations=1)\n",
    "    kernel = np.ones((1, 1), np.uint8)\n",
    "    image = cv2.erode(image, kernel, iterations=1)\n",
    "    image = cv2.morphologyEx(image, cv2.MORPH_CLOSE, kernel)\n",
    "    image = cv2.medianBlur(image, 3)\n",
    "    return (image)\n",
    "\n",
    "no_noise = noise_removal(im_bw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imwrite(\"../temp/result4.jpg\", no_noise)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 05: Dilation and Erosion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def thin_font(image):\n",
    "    import numpy as np\n",
    "    image = cv2.bitwise_not(image)\n",
    "    kernel = np.ones((2,2),np.uint8)\n",
    "    image = cv2.erode(image, kernel, iterations=1)\n",
    "    image = cv2.bitwise_not(image)\n",
    "    return (image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eroded_image = thin_font(no_noise)\n",
    "cv2.imwrite(\"../temp/result5.jpg\", eroded_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def thick_font(image):\n",
    "    import numpy as np\n",
    "    image = cv2.bitwise_not(image)\n",
    "    kernel = np.ones((2,2),np.uint8)\n",
    "    image = cv2.dilate(image, kernel, iterations=1)\n",
    "    image = cv2.bitwise_not(image)\n",
    "    return (image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dilated_image = thick_font(no_noise)\n",
    "cv2.imwrite(\"../temp/result6.jpg\", dilated_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
